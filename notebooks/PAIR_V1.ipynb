{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psychological Artificial Intelligence Research (PAIR) Project\n",
    "---\n",
    "**Author:** Tyler Chang | **Last Updated:** December 11, 2023 | **Code Repo:** TBD | **Contact:** TBD\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Project\n",
    "\n",
    "The **PAIR Project** is an ongoing effort to build AI frameworks for identifying psychological\n",
    "epidemics in populations during specific epochs. \n",
    "\n",
    "Begun in Spring 2023 by a team of 4 developers led by Tyler Chang, the first released content \n",
    "focused on building classification models that predict levels of dark triad traits relative to others \n",
    "based on the SD3 (*short dark triad*) questionnaire. The SD3 questionnaire includes questions \n",
    "meant to measure a person's level of psychopathy, narcissism, and Machiavellianism, and can be \n",
    "administered without the presence of a psychologist (it is **NOT** a diagnostic tool, \n",
    "regardless of whether a psychologist is present). The models developed were each trained \n",
    "on a subset of the questions associated with two of the three dark triad traits to predict \n",
    "a person's average score for questions associated with the third trait. With accuracies \n",
    "ranging between approximately 67-78%, the models provided limited insight into the \n",
    "connections between each of the dark triad traits. \n",
    "\n",
    "Following the initial release, the initial project team was disbanded (due to changing\n",
    "professional obligations) and further work was temporarily paused. Development resumed\n",
    "in late Summer 2023 and the project was restructured to focus on loneliness and Machiavellianism. \n",
    "\n",
    "### Information about the Project\n",
    "\n",
    "PAIR is an interdisciplinary project, utilizing research and techniques from psychology,\n",
    "data science, sociology, and ethical philosophy. \n",
    "\n",
    "The primary programming language used is Python (currently version 3.11.3). Additional \n",
    "languages, including R, SQL, HTML, and CSS, may be used to supplement the Python code \n",
    "where advisable. \n",
    "\n",
    "All current work (as of December 2023) is being developed by the Project Lead. No \n",
    "collaborators are currently being sought (the project is expected to be reopened to \n",
    "potential collaborators in January 2024). \n",
    "\n",
    "Data collection is expected to begin in January/February 2024 (I am currently working\n",
    "on a way to administer the questionnaire, obtain the time data, and ensure data\n",
    "privacy/security). The questionnaire is expected to contain the MACH-IV questions+survey, \n",
    "the SD3 questions, a loneliness assessment questionnaire (exact design currently being \n",
    "researched), and a time tracker component (time to answer individual questions + time to \n",
    "complete sections). Questions will be presented in English and will be shown in random \n",
    "order, with the optional personal information survey always being the final part (education\n",
    "level, age, gender, native language, religion, sexual orientation, ethnicity, nationality,\n",
    "marital status, number of children, number of siblings, and university major (if applicable)).\n",
    "\n",
    "### Disclaimers\n",
    "- This project's team does not currently include any medical professionals. \n",
    "No claims made in this report should be taken as a substitute for a medical\n",
    "diagnosis.\n",
    "- The data used in parts 1-3 has not been collected by the PAIR development team. \n",
    "As such, the findings of these sections should be taken as frameworks for use with\n",
    "live data (to be clear, the data used is real data but the PAIR team has not been\n",
    "able to verify that the advertised collection methods were followed or data integrity standards\n",
    "were met).\n",
    "- The project is ongoing and objectives may change as it progresses. If any significant\n",
    "changes are made, they will be reflected in the project's GitHub repo README and in \n",
    "the documentation of this report.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents (updated as work progresses; titles are subject to change)\n",
    "\n",
    "**Part 0: Loading Libraries and Importing Dataset**\n",
    "1. Loading all Libraries\n",
    "2. Importing the Datasets (parts 1-3)\n",
    "3. Connecting to Live Data (expected Spring 2023)\n",
    "\n",
    "**Part 1: MACH-IV 2017-2019**\n",
    "1. The MACH-IV Dataset\n",
    "2. Cleaning the Dataset\n",
    "3. Analysis of the Dataset\n",
    "4. Modeling the Dataset\n",
    "5. Conclusions\n",
    "\n",
    "**Part 2: SD3 [unknown time]**\n",
    "\n",
    "**Part 3: Loneliness Dataset (TBD)**\n",
    "\n",
    "**Part 4 Onward: Live Datasets (obtained via questionnaire)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Loading Libraries and Importing Datasets\n",
    "\n",
    "This section has 3 blocks of code:\n",
    "1. Loading all required libraries\n",
    "- Not all libraries may be used in every section.\n",
    "- I am loading all of the libraries here instead of per section for clarity-sake. \n",
    "It will be noted which libraries are required for each section if you wish to only\n",
    "load part of the report (or reproduce the code).\n",
    "2. Loading the MACH-IV, SD3, and Loneliness datasets\n",
    "- I am loading the data locally temporarily (so I can work offline while traveling); \n",
    "all datasets will be made accessible online via the project's GitHub repo (likely \n",
    "via links to sites better suited to storing larger dataset). \n",
    "- The loneliness dataset is currently being sought and may end up as multiple datasets.\n",
    "It is currently expected that this will involve extracting information from text instead\n",
    "of relying only on questionnaire-style information.\n",
    "3. Loading the Live questionnaire data\n",
    "- This will be connected directly to a database for ease of access and updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING ALL LIBRARIES (subject to change)\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc, make_scorer\n",
    "from xgboost import XGBClassifier   # I am loading this separately to make the code later shorter\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# NLP (may be used with loneliness dataset)\n",
    "\n",
    "# Deep Learning (depends on size of later datasets)\n",
    "\n",
    "# miscellaneous\n",
    "from IPython import display\n",
    "import joblib   # useful for saving a model\n",
    "from pandasql import sqldf  # required to use SQL commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING THE MACH-IV DATA\n",
    "\n",
    "# MACH-IV data\n",
    "mdf = pd.read_csv('data.csv', delimiter =\"\\t\")\n",
    "\n",
    "# SD3 data\n",
    "sdf = pd.read_csv('SD3/data.csv', delimiter = \"\\t\")\n",
    "\n",
    "# Loneliness data\n",
    "#ldf =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MACH-IV 2017-2019\n",
    "\n",
    "ADD PREAMBLE LATER\n",
    "- Explain what the MACH-IV survey consists of and how it is interpreted.\n",
    "- Add a summary of Part 1's contents\n",
    "- Add an appropriate image or graphic to better visually separate the section (do the \n",
    "same thing for subsequent sections)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the MACH-IV Data\n",
    "\n",
    "1. Overview of the dataset\n",
    "- table dimensions & peek at data\n",
    "- data types in the table (and how many of each type)\n",
    "2. Handling missing values\n",
    "3. Handling improper values\n",
    "- Keep in mind that the dataset includes a checker for whether a person may be lying\n",
    "(there is a section in the survey that asks respondents if they are sure they know \n",
    "the definition of a series of words; three of the words are fake words, meaning a \n",
    "person who says they know their definitions may be lying about their responses (they\n",
    "may also be confusing it for another word)).\n",
    "4. Changing the time values to seconds (they are in milliseconds by default)\n",
    "5. Final checks (basically reconfirm that there are no missing or improper values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73489 entries, 0 to 73488\n",
      "Columns: 105 entries, Q1A to major\n",
      "dtypes: float64(64), int64(39), object(2)\n",
      "memory usage: 58.9+ MB\n"
     ]
    }
   ],
   "source": [
    "### TABLE DIMENSIONS\n",
    "mdf.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw dataset includes 73,489 rows (respondents) and 105 columns (features), with 103 numeric and 2 text-based columns. This \n",
    "size is expected to be sufficient to train a non-deep model but is likely too small to built a robust deep model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q1I</th>\n",
       "      <th>Q1E</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2I</th>\n",
       "      <th>Q2E</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q3I</th>\n",
       "      <th>Q3E</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>...</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>hand</th>\n",
       "      <th>religion</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>voted</th>\n",
       "      <th>married</th>\n",
       "      <th>familysize</th>\n",
       "      <th>major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21017.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14957.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3818.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5902.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4186.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>375.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A   Q1I      Q1E  Q2A   Q2I      Q2E  Q3A   Q3I      Q3E  Q4A  ...  \\\n",
       "0  3.0   6.0  21017.0  3.0   7.0  18600.0  5.0  20.0  14957.0  2.0  ...   \n",
       "1  5.0  17.0   3818.0  5.0   9.0   7850.0  1.0  16.0   5902.0  3.0  ...   \n",
       "2  5.0  16.0   4186.0  5.0  12.0   2900.0  1.0   2.0   7160.0  1.0  ...   \n",
       "\n",
       "   screenw  screenh  hand  religion  orientation  race  voted  married  \\\n",
       "0   1440.0    900.0     1         7            1    30      1        2   \n",
       "1   1536.0    864.0     1         1            1    60      2        1   \n",
       "2    375.0    667.0     1         2            2    10      2        1   \n",
       "\n",
       "   familysize        major  \n",
       "0           5   Marketing   \n",
       "1           2  mathematics  \n",
       "2           2    Chemistry  \n",
       "\n",
       "[3 rows x 105 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LOOKING AT THE TABLE\n",
    "mdf.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the columns where answers would be expected to be non-numeric have already been encoded. They include:\n",
    "married, voted, race, orientation, religion, hand, engnat (\"English native\"), gender, urban, and education. For ease of\n",
    "translating these encoded values into readable formats later, I have created a dictionary with their respective values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DICTIONAIRES FOR TRANSLATING ENCODED FEATURES\n",
    "\"\"\"\n",
    "I am making a dictionary for each of the features that are not straightforward\n",
    "to interpret.\n",
    "\"\"\"\n",
    "marriage_dict = {1: 'Never married', 2: 'Currently married', 3: 'Previously married'}\n",
    "voted_dict = {1: 'Yes', 2: 'No'}    # this is if the person voted in a national election in the last year\n",
    "race_dict = {10: 'Asian', 20: 'Arab', 30: 'Black', 40: 'Indigenous Australian',\n",
    "             50: 'Native American', 60: 'White', 70: 'Other'}\n",
    "sex_orient_dict = {1: 'Heterosexual', 2: 'Bisexual', 3: 'Homosexual',\n",
    "                   4: 'Asexual', 5: 'Other'}\n",
    "religion_dict = {1: 'Agnostic', 2: 'Atheist', 3: 'Buddhist', 4: 'Catholic',\n",
    "                 5: 'Mormon', 6: 'Protestant', 7: 'Christian (Other)',\n",
    "                 8: 'Hindu', 9: 'Jewish', 10: 'Muslim', 11: 'Sikh',\n",
    "                 12: 'Other'}\n",
    "hand_dict = {1: 'Right', 2: 'Left', 3: 'Both'}   # this is which hand you write with\n",
    "engnat_dict = {1: 'Yes', 2: 'No'}   # this is whether English is your native language\n",
    "gender_dict = {1: 'Male', 2: 'Female', 3: 'Other'}\n",
    "urban_dict = {1: 'Rural (country side)', 2: 'Suburban', 3: 'Urban (town/city)'} # this is where you grew up\n",
    "education_dict = {1: 'Less than high school', 2: 'High school',\n",
    "                  3: 'University degree', 4: 'Graduate degree'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now check if there are any missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECKING FOR MISSING VALUES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling (Clusters, question scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions (findings, further work, ethical concerns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: SD3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
